{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeEJK48qS6_1"
      },
      "source": [
        "# Задание 3.2 - сверточные нейронные сети (CNNs) в PyTorch\n",
        "\n",
        "Это упражнение мы буде выполнять в Google Colab - https://colab.research.google.com/  \n",
        "Google Colab позволяет запускать код в notebook в облаке Google, где можно воспользоваться бесплатным GPU!  \n",
        "\n",
        "Авторы курса благодарят компанию Google и надеятся, что праздник не закончится.\n",
        "\n",
        "Туториал по настройке Google Colab:  \n",
        "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d  \n",
        "(Keras инсталлировать не нужно, наш notebook сам установит PyTorch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcXBeP1O7cnY",
        "outputId": "d42894dd-c553-44ba-dd52-f7927fd74e4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "--2023-05-21 06:00:57--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182040794 (174M) [text/plain]\n",
            "Saving to: ‘train_32x32.mat’\n",
            "\n",
            "train_32x32.mat     100%[===================>] 173.61M  21.9MB/s    in 9.0s    \n",
            "\n",
            "2023-05-21 06:01:06 (19.3 MB/s) - ‘train_32x32.mat’ saved [182040794/182040794]\n",
            "\n",
            "--2023-05-21 06:01:06--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
            "Reusing existing connection to ufldl.stanford.edu:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64275384 (61M) [text/plain]\n",
            "Saving to: ‘test_32x32.mat’\n",
            "\n",
            "test_32x32.mat      100%[===================>]  61.30M  31.5MB/s    in 1.9s    \n",
            "\n",
            "2023-05-21 06:01:08 (31.5 MB/s) - ‘test_32x32.mat’ saved [64275384/64275384]\n",
            "\n",
            "FINISHED --2023-05-21 06:01:08--\n",
            "Total wall clock time: 11s\n",
            "Downloaded: 2 files, 235M in 11s (21.5 MB/s)\n"
          ]
        }
      ],
      "source": [
        "# Intstall PyTorch and download data\n",
        "!pip3 install torch torchvision\n",
        "\n",
        "!wget -c http://ufldl.stanford.edu/housenumbers/train_32x32.mat http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-afwWw-Q85vD"
      },
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNU-OD9O9ltP"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\") # Let's make sure GPU is available!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC8Z1mZhS6__"
      },
      "source": [
        "# Загружаем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAvkoRx-9FsP"
      },
      "outputs": [],
      "source": [
        "# First, lets load the dataset\n",
        "data_train = dset.SVHN('./', \n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
        "                                               std=[0.20,0.20,0.20])                           \n",
        "                       ])\n",
        "                      )\n",
        "data_test = dset.SVHN('./', split='test', transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
        "                                               std=[0.20,0.20,0.20])                           \n",
        "                       ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QApBskGoS7AA"
      },
      "source": [
        "Разделяем данные на training и validation.\n",
        "\n",
        "На всякий случай для подробностей - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRnr8CPg7Hli"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "data_size = data_train.data.shape[0]\n",
        "validation_split = .2\n",
        "split = int(np.floor(validation_split * data_size))\n",
        "indices = list(range(data_size))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
        "                                         sampler=val_sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyYvt-T67PBG"
      },
      "outputs": [],
      "source": [
        "# We'll use a special helper module to shape it into a flat tensor\n",
        "class Flattener(nn.Module):\n",
        "    def forward(self, x):\n",
        "        batch_size, *_ = x.shape\n",
        "        return x.view(batch_size, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33shZHCmS7AD"
      },
      "source": [
        "Создадим простейшую сеть с новыми слоями:  \n",
        "Convolutional - `nn.Conv2d`  \n",
        "MaxPool - `nn.MaxPool2d`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9SFVGZP7SQd"
      },
      "outputs": [],
      "source": [
        "nn_model = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(4),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(4),    \n",
        "            Flattener(),\n",
        "            nn.Linear(64*2*2, 10),\n",
        "          )\n",
        "\n",
        "nn_model.type(torch.cuda.FloatTensor)\n",
        "nn_model.to(device)\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "optimizer = optim.SGD(nn_model.parameters(), lr=1e-1, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtX1n61RS7AE"
      },
      "source": [
        "Восстановите функцию `compute_accuracy` из прошлого задания.  \n",
        "Единственное отличие в новом - она должна передать данные на GPU прежде чем прогонять через модель. Сделайте это так же, как это делает функция `train_model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ek3KVQK7hJ6"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):    \n",
        "    loss_history = []\n",
        "    train_history = []\n",
        "    val_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train() # Enter train mode\n",
        "        \n",
        "        loss_accum = 0\n",
        "        correct_samples = 0\n",
        "        total_samples = 0\n",
        "        for i_step, (x, y) in enumerate(train_loader):\n",
        "          \n",
        "            x_gpu = x.to(device)\n",
        "            y_gpu = y.to(device)\n",
        "            prediction = model(x_gpu)    \n",
        "            loss_value = loss(prediction, y_gpu)\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            _, indices = torch.max(prediction, 1)\n",
        "            correct_samples += torch.sum(indices == y_gpu)\n",
        "            total_samples += y.shape[0]\n",
        "            \n",
        "            loss_accum += loss_value\n",
        "\n",
        "        ave_loss = loss_accum / i_step\n",
        "        train_accuracy = float(correct_samples) / total_samples\n",
        "        val_accuracy = compute_accuracy(model, val_loader)\n",
        "        \n",
        "        loss_history.append(float(ave_loss))\n",
        "        train_history.append(train_accuracy)\n",
        "        val_history.append(val_accuracy)\n",
        "        \n",
        "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
        "        \n",
        "    return loss_history, train_history, val_history\n",
        "        \n",
        "def compute_accuracy(model, loader):\n",
        "    \"\"\"\n",
        "    Computes accuracy on the dataset wrapped in a loader\n",
        "    \n",
        "    Returns: accuracy as a float value between 0 and 1\n",
        "    \"\"\"\n",
        "    model.eval() # Evaluation mode\n",
        "    # TODO: Copy implementation from previous assignment\n",
        "    # Don't forget to move the data to device before running it through the model!\n",
        "    correct_num = 0\n",
        "    total_num = 0\n",
        "    for data in loader:\n",
        "        x, y = data\n",
        "        x_gpu = x.to(device)\n",
        "        y_gpu = y.to(device)\n",
        "        prediction = model(x_gpu)\n",
        "\n",
        "        _, idx = torch.max(prediction, 1)\n",
        "        correct_num += torch.sum(idx == y_gpu)\n",
        "        total_num += y.shape[0]\n",
        "    \n",
        "    return correct_num / total_num"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 5)"
      ],
      "metadata": {
        "id": "W5mOjopK5qob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a-3a1ZFGEw_"
      },
      "source": [
        "# Аугментация данных (Data augmentation)\n",
        "\n",
        "В работе с изображениями одним из особенно важных методов является аугментация данных - то есть, генерация дополнительных данных для тренировки на основе изначальных.   \n",
        "Таким образом, мы получаем возможность \"увеличить\" набор данных для тренировки, что ведет к лучшей работе сети.\n",
        "Важно, чтобы аугментированные данные были похожи на те, которые могут встретиться в реальной жизни, иначе польза от аугментаций уменьшается и может ухудшить работу сети.\n",
        "\n",
        "С PyTorch идут несколько таких алгоритмов, называемых `transforms`. Более подробно про них можно прочитать тут -\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#transforms\n",
        "\n",
        "Ниже мы используем следующие алгоритмы генерации:\n",
        "- ColorJitter - случайное изменение цвета\n",
        "- RandomHorizontalFlip - горизонтальное отражение с вероятностью 50%\n",
        "- RandomVerticalFlip - вертикальное отражение с вероятностью 50%\n",
        "- RandomRotation - случайный поворот"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCWMUWmr7t5g"
      },
      "outputs": [],
      "source": [
        "tfs = transforms.Compose([\n",
        "    transforms.ColorJitter(hue=.50, saturation=.50),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(50, interpolation=PIL.Image.BILINEAR),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.43,0.44,0.47],\n",
        "                       std=[0.20,0.20,0.20])                           \n",
        "])\n",
        "\n",
        "# Create augmented train dataset\n",
        "data_aug_train = dset.SVHN('./', \n",
        "                       transform=tfs\n",
        "                      )\n",
        "\n",
        "train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQeWK587S7AG"
      },
      "source": [
        "Визуализируем результаты агментации (вообще, смотреть на сгенерированные данные всегда очень полезно)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlJJEro1KZ45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "72ae8a7b-54dd-4315-ac37-c99c550ca9ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3000x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Visualize some augmented images!\n",
        "# hint: you can create new datasets and loaders to accomplish this\n",
        "\n",
        "# Based on the visualizations, should we keep all the augmentations?\n",
        "\n",
        "tfs = transforms.Compose([\n",
        "    transforms.ColorJitter(hue=.20, saturation=.20),\n",
        "    transforms.RandomRotation(10, interpolation=PIL.Image.BILINEAR),\n",
        "])\n",
        "\n",
        "data_aug_vis = dset.SVHN('./', transform=tfs)\n",
        "\n",
        "plt.figure(figsize=(30, 3))\n",
        "\n",
        "for i, (x, y) in enumerate(data_aug_vis):\n",
        "    if i == 10:\n",
        "        break\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x)\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2LrmsYHoguB"
      },
      "source": [
        "Все ли агментации одинаково полезны на этом наборе данных? Могут ли быть среди них те, которые собьют модель с толку?\n",
        "\n",
        "Выберите из них только корректные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evro9ksXGs9u"
      },
      "outputs": [],
      "source": [
        "# TODO: \n",
        "tfs = transforms.Compose([\n",
        "    # TODO: Add good augmentations\n",
        "    transforms.ColorJitter(hue=.20, saturation=.20),\n",
        "    transforms.RandomRotation(10, interpolation=PIL.Image.BILINEAR),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.43,0.44,0.47],\n",
        "                       std=[0.20,0.20,0.20])                           \n",
        "])\n",
        "\n",
        "# TODO create new instances of loaders with the augmentations you chose\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "new_data_aug = dset.SVHN('./', transform=tfs)\n",
        "\n",
        "data_size = new_data_aug.data.shape[0]\n",
        "val_split = 0.2\n",
        "indices = list(range(data_size))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_sampler = SubsetRandomSampler(indices)\n",
        "\n",
        "train_loader_aug = torch.utils.data.DataLoader(new_data_aug, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeO6Zw0DHqPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f537e248-6dc2-42de-ad35-648386b77c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 0.593524, Train accuracy: 0.818215, Val accuracy: 0.837554\n",
            "Average loss: 0.542338, Train accuracy: 0.835797, Val accuracy: 0.843355\n",
            "Average loss: 0.517212, Train accuracy: 0.843373, Val accuracy: 0.866016\n",
            "Average loss: 0.501129, Train accuracy: 0.848260, Val accuracy: 0.859464\n",
            "Average loss: 0.488084, Train accuracy: 0.852082, Val accuracy: 0.870384\n"
          ]
        }
      ],
      "source": [
        "# Finally, let's train with augmentations!\n",
        "\n",
        "# Note we shouldn't use augmentations on validation\n",
        "\n",
        "loss_history, train_history, val_history = train_model(nn_model, train_loader_aug, val_loader, loss, optimizer, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0bcioK6JBDK"
      },
      "source": [
        "# LeNet\n",
        "Попробуем имплементировать классическую архитектуру сверточной нейронной сети, предложенную Яном ЛеКуном в 1998 году. В свое время она достигла впечатляющих результатов на MNIST, посмотрим как она справится с SVHN?\n",
        "Она описана в статье [\"Gradient Based Learning Applied to Document Recognition\"](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), попробуйте прочитать ключевые части и имплементировать предложенную архитетуру на PyTorch.\n",
        "\n",
        "Реализовывать слои и функцию ошибки LeNet, которых нет в PyTorch, **не нужно** - просто возьмите их размеры и переведите в уже известные нам Convolutional, Pooling и Fully Connected layers.\n",
        "\n",
        "Если в статье не очень понятно, можно просто погуглить LeNet и разобраться в деталях :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieEzZUglJAUB"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement LeNet-like architecture for SVHN task\n",
        "lenet_model = nn.Sequential(\n",
        "    nn.Conv2d(3, 6, 5),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(6, 16, 5),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(2),    \n",
        "    Flattener(),\n",
        "    nn.Linear(400, 120),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(120, 84),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(84, 10),\n",
        "    nn.LogSoftmax(dim=-1)\n",
        "          )\n",
        "\n",
        "lenet_model.type(torch.cuda.FloatTensor)\n",
        "lenet_model.to(device)\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "optimizer = optim.SGD(lenet_model.parameters(), lr=1e-1, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfs = transforms.Compose([\n",
        "    transforms.ColorJitter(hue=.50, saturation=.50),\n",
        "    transforms.RandomRotation(50, interpolation=PIL.Image.BILINEAR),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.43,0.44,0.47],\n",
        "                       std=[0.20,0.20,0.20])                           \n",
        "])\n",
        "\n",
        "# Create augmented train dataset\n",
        "data_aug_train = dset.SVHN('./', transform=tfs)\n",
        "\n",
        "train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)"
      ],
      "metadata": {
        "id": "uBPcCJ0n_Ui_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMmaPfdeKk9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c89514-335d-4ff2-c8a4-2a5df1d3c1bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.626300, Train accuracy: 0.438770, Val accuracy: 0.719951\n",
            "Average loss: 0.768369, Train accuracy: 0.764623, Val accuracy: 0.806839\n",
            "Average loss: 0.640800, Train accuracy: 0.805124, Val accuracy: 0.816804\n",
            "Average loss: 0.586074, Train accuracy: 0.821751, Val accuracy: 0.825541\n",
            "Average loss: 0.544728, Train accuracy: 0.835497, Val accuracy: 0.845744\n",
            "Average loss: 0.523006, Train accuracy: 0.842158, Val accuracy: 0.852570\n",
            "Average loss: 0.501930, Train accuracy: 0.848328, Val accuracy: 0.843014\n",
            "Average loss: 0.493500, Train accuracy: 0.851550, Val accuracy: 0.871135\n",
            "Average loss: 0.483666, Train accuracy: 0.855126, Val accuracy: 0.877483\n",
            "Average loss: 0.467545, Train accuracy: 0.859781, Val accuracy: 0.871272\n"
          ]
        }
      ],
      "source": [
        "# Let's train it!\n",
        "loss_history, train_history, val_history = train_model(lenet_model, train_aug_loader, val_loader, loss, optimizer, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_O9qiYySvuj"
      },
      "source": [
        "# Подбор гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6mhfdQ9K-N3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af113323-851c-461e-9442-de3a0355429b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "learning_rate: 0.1   aneal_epochs: 1   weight_decay: 0.001\n",
            "Average loss: 0.908358, Train accuracy: 0.720259, Val accuracy: 0.755512\n",
            "Average loss: 0.738686, Train accuracy: 0.773196, Val accuracy: 0.791823\n",
            "Average loss: 0.700602, Train accuracy: 0.785440, Val accuracy: 0.801242\n",
            "Average loss: 0.689442, Train accuracy: 0.787638, Val accuracy: 0.802334\n",
            "Average loss: 0.690843, Train accuracy: 0.788689, Val accuracy: 0.803085\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 1   weight_decay: 0.0001\n",
            "Average loss: 0.906086, Train accuracy: 0.719863, Val accuracy: 0.748618\n",
            "Average loss: 0.729819, Train accuracy: 0.775257, Val accuracy: 0.791072\n",
            "Average loss: 0.686177, Train accuracy: 0.787652, Val accuracy: 0.802812\n",
            "Average loss: 0.680131, Train accuracy: 0.791583, Val accuracy: 0.804996\n",
            "Average loss: 0.678821, Train accuracy: 0.791556, Val accuracy: 0.804655\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 1   weight_decay: 1e-05\n",
            "Average loss: 0.895089, Train accuracy: 0.724258, Val accuracy: 0.751689\n",
            "Average loss: 0.722151, Train accuracy: 0.780512, Val accuracy: 0.795987\n",
            "Average loss: 0.685345, Train accuracy: 0.789836, Val accuracy: 0.804177\n",
            "Average loss: 0.675373, Train accuracy: 0.793276, Val accuracy: 0.804041\n",
            "Average loss: 0.676054, Train accuracy: 0.792525, Val accuracy: 0.804587\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 1   weight_decay: 1e-07\n",
            "Average loss: 0.887351, Train accuracy: 0.724463, Val accuracy: 0.744181\n",
            "Average loss: 0.719028, Train accuracy: 0.780267, Val accuracy: 0.802949\n",
            "Average loss: 0.678105, Train accuracy: 0.791665, Val accuracy: 0.806498\n",
            "Average loss: 0.670225, Train accuracy: 0.793303, Val accuracy: 0.808614\n",
            "Average loss: 0.669733, Train accuracy: 0.794682, Val accuracy: 0.808204\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 2   weight_decay: 0.001\n",
            "Average loss: 0.875665, Train accuracy: 0.729664, Val accuracy: 0.720019\n",
            "Average loss: 0.863646, Train accuracy: 0.730292, Val accuracy: 0.750529\n",
            "Average loss: 0.704356, Train accuracy: 0.783775, Val accuracy: 0.805815\n",
            "Average loss: 0.679328, Train accuracy: 0.789085, Val accuracy: 0.806430\n",
            "Average loss: 0.650286, Train accuracy: 0.798613, Val accuracy: 0.816668\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 2   weight_decay: 0.0001\n",
            "Average loss: 0.875355, Train accuracy: 0.729514, Val accuracy: 0.707392\n",
            "Average loss: 0.868573, Train accuracy: 0.729596, Val accuracy: 0.664187\n",
            "Average loss: 0.700891, Train accuracy: 0.787092, Val accuracy: 0.802471\n",
            "Average loss: 0.677960, Train accuracy: 0.791952, Val accuracy: 0.807453\n",
            "Average loss: 0.647523, Train accuracy: 0.800674, Val accuracy: 0.816395\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 2   weight_decay: 1e-05\n",
            "Average loss: 0.862262, Train accuracy: 0.734892, Val accuracy: 0.752167\n",
            "Average loss: 0.855657, Train accuracy: 0.735029, Val accuracy: 0.738789\n",
            "Average loss: 0.691630, Train accuracy: 0.789781, Val accuracy: 0.802471\n",
            "Average loss: 0.667306, Train accuracy: 0.794272, Val accuracy: 0.806361\n",
            "Average loss: 0.639073, Train accuracy: 0.804456, Val accuracy: 0.813665\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 2   weight_decay: 1e-07\n",
            "Average loss: 0.859047, Train accuracy: 0.735370, Val accuracy: 0.737697\n",
            "Average loss: 0.853436, Train accuracy: 0.737732, Val accuracy: 0.765204\n",
            "Average loss: 0.682470, Train accuracy: 0.791133, Val accuracy: 0.802744\n",
            "Average loss: 0.663311, Train accuracy: 0.795910, Val accuracy: 0.806839\n",
            "Average loss: 0.639347, Train accuracy: 0.803213, Val accuracy: 0.817009\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 3   weight_decay: 0.001\n",
            "Average loss: 0.842205, Train accuracy: 0.738086, Val accuracy: 0.701386\n",
            "Average loss: 0.843931, Train accuracy: 0.738264, Val accuracy: 0.769640\n",
            "Average loss: 0.844279, Train accuracy: 0.738769, Val accuracy: 0.758993\n",
            "Average loss: 0.678125, Train accuracy: 0.791542, Val accuracy: 0.804041\n",
            "Average loss: 0.657868, Train accuracy: 0.797780, Val accuracy: 0.812368\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 3   weight_decay: 0.0001\n",
            "Average loss: 0.854686, Train accuracy: 0.736162, Val accuracy: 0.749437\n",
            "Average loss: 0.848545, Train accuracy: 0.737568, Val accuracy: 0.742202\n",
            "Average loss: 0.842885, Train accuracy: 0.740516, Val accuracy: 0.728141\n",
            "Average loss: 0.681396, Train accuracy: 0.790996, Val accuracy: 0.801788\n",
            "Average loss: 0.658921, Train accuracy: 0.798995, Val accuracy: 0.806566\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 3   weight_decay: 1e-05\n",
            "Average loss: 0.842453, Train accuracy: 0.741240, Val accuracy: 0.765272\n",
            "Average loss: 0.842590, Train accuracy: 0.739779, Val accuracy: 0.757218\n",
            "Average loss: 0.837236, Train accuracy: 0.743574, Val accuracy: 0.757150\n",
            "Average loss: 0.679345, Train accuracy: 0.792416, Val accuracy: 0.811207\n",
            "Average loss: 0.659463, Train accuracy: 0.797630, Val accuracy: 0.811890\n",
            "\n",
            "learning_rate: 0.1   aneal_epochs: 3   weight_decay: 1e-07\n",
            "Average loss: 0.827734, Train accuracy: 0.744721, Val accuracy: 0.752713\n",
            "Average loss: 0.832100, Train accuracy: 0.743943, Val accuracy: 0.725889\n",
            "Average loss: 0.835143, Train accuracy: 0.744953, Val accuracy: 0.747389\n",
            "Average loss: 0.674066, Train accuracy: 0.794900, Val accuracy: 0.808545\n",
            "Average loss: 0.646047, Train accuracy: 0.803268, Val accuracy: 0.813665\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 1   weight_decay: 0.001\n",
            "Average loss: 0.627811, Train accuracy: 0.808237, Val accuracy: 0.819808\n",
            "Average loss: 0.609097, Train accuracy: 0.813028, Val accuracy: 0.823289\n",
            "Average loss: 0.609658, Train accuracy: 0.812400, Val accuracy: 0.825268\n",
            "Average loss: 0.606942, Train accuracy: 0.814025, Val accuracy: 0.825882\n",
            "Average loss: 0.608083, Train accuracy: 0.814052, Val accuracy: 0.826019\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 1   weight_decay: 0.0001\n",
            "Average loss: 0.619985, Train accuracy: 0.808360, Val accuracy: 0.821173\n",
            "Average loss: 0.607994, Train accuracy: 0.813752, Val accuracy: 0.825063\n",
            "Average loss: 0.602432, Train accuracy: 0.814857, Val accuracy: 0.825268\n",
            "Average loss: 0.600881, Train accuracy: 0.816536, Val accuracy: 0.825404\n",
            "Average loss: 0.603651, Train accuracy: 0.815117, Val accuracy: 0.825541\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 1   weight_decay: 1e-05\n",
            "Average loss: 0.611878, Train accuracy: 0.812946, Val accuracy: 0.818988\n",
            "Average loss: 0.604295, Train accuracy: 0.814844, Val accuracy: 0.825268\n",
            "Average loss: 0.601142, Train accuracy: 0.815826, Val accuracy: 0.825882\n",
            "Average loss: 0.596386, Train accuracy: 0.817314, Val accuracy: 0.826360\n",
            "Average loss: 0.597261, Train accuracy: 0.817314, Val accuracy: 0.826428\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 1   weight_decay: 1e-07\n",
            "Average loss: 0.612942, Train accuracy: 0.811581, Val accuracy: 0.818920\n",
            "Average loss: 0.601105, Train accuracy: 0.815840, Val accuracy: 0.825473\n",
            "Average loss: 0.593467, Train accuracy: 0.818980, Val accuracy: 0.826087\n",
            "Average loss: 0.598293, Train accuracy: 0.816154, Val accuracy: 0.825609\n",
            "Average loss: 0.595472, Train accuracy: 0.817710, Val accuracy: 0.825677\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 2   weight_decay: 0.001\n",
            "Average loss: 0.605890, Train accuracy: 0.814625, Val accuracy: 0.823425\n",
            "Average loss: 0.606003, Train accuracy: 0.814871, Val accuracy: 0.824927\n",
            "Average loss: 0.595260, Train accuracy: 0.816536, Val accuracy: 0.826633\n",
            "Average loss: 0.592004, Train accuracy: 0.819157, Val accuracy: 0.828066\n",
            "Average loss: 0.590983, Train accuracy: 0.819485, Val accuracy: 0.828885\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 2   weight_decay: 0.0001\n",
            "Average loss: 0.602362, Train accuracy: 0.814871, Val accuracy: 0.825404\n",
            "Average loss: 0.602336, Train accuracy: 0.814461, Val accuracy: 0.824244\n",
            "Average loss: 0.589545, Train accuracy: 0.819908, Val accuracy: 0.828681\n",
            "Average loss: 0.589297, Train accuracy: 0.818843, Val accuracy: 0.828271\n",
            "Average loss: 0.587375, Train accuracy: 0.819608, Val accuracy: 0.828954\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 2   weight_decay: 1e-05\n",
            "Average loss: 0.598503, Train accuracy: 0.816099, Val accuracy: 0.824722\n",
            "Average loss: 0.599275, Train accuracy: 0.815144, Val accuracy: 0.824449\n",
            "Average loss: 0.585178, Train accuracy: 0.821382, Val accuracy: 0.830592\n",
            "Average loss: 0.581238, Train accuracy: 0.821601, Val accuracy: 0.830114\n",
            "Average loss: 0.580081, Train accuracy: 0.822556, Val accuracy: 0.832435\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 2   weight_decay: 1e-07\n",
            "Average loss: 0.597317, Train accuracy: 0.815867, Val accuracy: 0.824517\n",
            "Average loss: 0.591354, Train accuracy: 0.818652, Val accuracy: 0.827657\n",
            "Average loss: 0.581634, Train accuracy: 0.820727, Val accuracy: 0.828817\n",
            "Average loss: 0.581260, Train accuracy: 0.821205, Val accuracy: 0.833185\n",
            "Average loss: 0.579158, Train accuracy: 0.823061, Val accuracy: 0.832844\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 3   weight_decay: 0.001\n",
            "Average loss: 0.594934, Train accuracy: 0.816837, Val accuracy: 0.826838\n",
            "Average loss: 0.593091, Train accuracy: 0.816673, Val accuracy: 0.826974\n",
            "Average loss: 0.594027, Train accuracy: 0.817151, Val accuracy: 0.827384\n",
            "Average loss: 0.578201, Train accuracy: 0.822379, Val accuracy: 0.833254\n",
            "Average loss: 0.576682, Train accuracy: 0.823498, Val accuracy: 0.833868\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 3   weight_decay: 0.0001\n",
            "Average loss: 0.591203, Train accuracy: 0.819430, Val accuracy: 0.832093\n",
            "Average loss: 0.589502, Train accuracy: 0.817779, Val accuracy: 0.826223\n",
            "Average loss: 0.587390, Train accuracy: 0.818912, Val accuracy: 0.827043\n",
            "Average loss: 0.578750, Train accuracy: 0.820700, Val accuracy: 0.834073\n",
            "Average loss: 0.574186, Train accuracy: 0.823184, Val accuracy: 0.834687\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 3   weight_decay: 1e-05\n",
            "Average loss: 0.583759, Train accuracy: 0.820973, Val accuracy: 0.828066\n",
            "Average loss: 0.589358, Train accuracy: 0.818638, Val accuracy: 0.831343\n",
            "Average loss: 0.587636, Train accuracy: 0.819185, Val accuracy: 0.822401\n",
            "Average loss: 0.574423, Train accuracy: 0.823293, Val accuracy: 0.833663\n",
            "Average loss: 0.567574, Train accuracy: 0.825204, Val accuracy: 0.832844\n",
            "\n",
            "learning_rate: 0.01   aneal_epochs: 3   weight_decay: 1e-07\n",
            "Average loss: 0.588373, Train accuracy: 0.817437, Val accuracy: 0.828203\n",
            "Average loss: 0.587083, Train accuracy: 0.820236, Val accuracy: 0.826633\n",
            "Average loss: 0.584516, Train accuracy: 0.819867, Val accuracy: 0.827862\n",
            "Average loss: 0.566844, Train accuracy: 0.825737, Val accuracy: 0.833527\n",
            "Average loss: 0.566563, Train accuracy: 0.826474, Val accuracy: 0.834755\n",
            "\n",
            "learning_rate: 0.001   aneal_epochs: 1   weight_decay: 0.001\n",
            "Average loss: 0.563312, Train accuracy: 0.828003, Val accuracy: 0.835643\n",
            "Average loss: 0.566349, Train accuracy: 0.827894, Val accuracy: 0.836052\n",
            "Average loss: 0.564778, Train accuracy: 0.827020, Val accuracy: 0.836257\n",
            "Average loss: 0.564429, Train accuracy: 0.826283, Val accuracy: 0.836052\n",
            "Average loss: 0.563623, Train accuracy: 0.827211, Val accuracy: 0.836120\n",
            "\n",
            "learning_rate: 0.001   aneal_epochs: 1   weight_decay: 0.0001\n",
            "Average loss: 0.564431, Train accuracy: 0.827088, Val accuracy: 0.836052\n",
            "Average loss: 0.563348, Train accuracy: 0.827593, Val accuracy: 0.836052\n",
            "Average loss: 0.562241, Train accuracy: 0.828208, Val accuracy: 0.836189\n",
            "Average loss: 0.563443, Train accuracy: 0.827006, Val accuracy: 0.836052\n",
            "Average loss: 0.561717, Train accuracy: 0.827798, Val accuracy: 0.835984\n",
            "\n",
            "learning_rate: 0.001   aneal_epochs: 1   weight_decay: 1e-05\n",
            "Average loss: 0.563967, Train accuracy: 0.828289, Val accuracy: 0.835028\n",
            "Average loss: 0.564288, Train accuracy: 0.827948, Val accuracy: 0.835643\n",
            "Average loss: 0.563354, Train accuracy: 0.826911, Val accuracy: 0.835643\n",
            "Average loss: 0.562809, Train accuracy: 0.827252, Val accuracy: 0.835779\n",
            "Average loss: 0.563434, Train accuracy: 0.826679, Val accuracy: 0.835643\n",
            "\n",
            "learning_rate: 0.001   aneal_epochs: 1   weight_decay: 1e-07\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-eeeda8e03aef>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nlearning_rate: {lr}   aneal_epochs: {epochs}   weight_decay: {reg}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_aug_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manneal_coeff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mrun_record\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHyperparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-eeeda8e03aef>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, loss, optimizer, num_epochs, step_size_scheduler, gamma_scheduler)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mx_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/svhn.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1377\u001b[0m         \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0mcenter_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(self, angle, resample, expand, center, translate, fillcolor)\u001b[0m\n\u001b[1;32m   2154\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAFFINE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfillcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, size, method, data, resample, fill, fillcolor)\u001b[0m\n\u001b[1;32m   2495\u001b[0m                 \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQUAD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2497\u001b[0;31m             im.__transformer(\n\u001b[0m\u001b[1;32m   2498\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__transformer\u001b[0;34m(self, box, image, method, data, resample, fill)\u001b[0m\n\u001b[1;32m   2572\u001b[0m             \u001b[0mresample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# The key hyperparameters we're going to tune are learning speed, annealing rate and regularization\n",
        "# We also encourage you to try different optimizers as well\n",
        "\n",
        "Hyperparams = namedtuple(\"Hyperparams\", ['learning_rate', 'anneal_epochs', 'reg'])\n",
        "RunResult = namedtuple(\"RunResult\", ['model', 'train_history', 'val_history', 'final_val_accuracy'])\n",
        "\n",
        "learning_rates = [1e-1, 1e-2, 1e-3, 1e-4]\n",
        "anneal_coeff = 0.2\n",
        "anneal_epochs = [1, 2, 3]\n",
        "regs = [1e-3, 1e-4, 1e-5, 1e-7]\n",
        "\n",
        "batch_size = 64\n",
        "epoch_num = 10\n",
        "\n",
        "# Record all the runs here\n",
        "# Key should be Hyperparams and values should be RunResult\n",
        "run_record = {} \n",
        "\n",
        "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, step_size_scheduler, gamma_scheduler):    \n",
        "    loss_history = []\n",
        "    train_history = []\n",
        "    val_history = []\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size_scheduler, gamma=gamma_scheduler)   \n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train() # Enter train mode\n",
        "        \n",
        "        loss_accum = 0\n",
        "        correct_samples = 0\n",
        "        total_samples = 0\n",
        "        if epoch != 0:\n",
        "            scheduler.step()\n",
        "        for i_step, (x, y) in enumerate(train_loader):\n",
        "          \n",
        "            x_gpu = x.to(device)\n",
        "            y_gpu = y.to(device)\n",
        "            prediction = model(x_gpu)    \n",
        "            loss_value = loss(prediction, y_gpu)\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            _, indices = torch.max(prediction, 1)\n",
        "            correct_samples += torch.sum(indices == y_gpu)\n",
        "            total_samples += y.shape[0]\n",
        "            \n",
        "            loss_accum += loss_value\n",
        "\n",
        "        ave_loss = loss_accum / i_step\n",
        "        train_accuracy = float(correct_samples) / total_samples\n",
        "        val_accuracy = compute_accuracy(model, val_loader)\n",
        "        \n",
        "        loss_history.append(float(ave_loss))\n",
        "        train_history.append(train_accuracy)\n",
        "        val_history.append(val_accuracy)\n",
        "        \n",
        "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
        "        \n",
        "    return loss_history, train_history, val_history\n",
        "\n",
        "# Use grid search or random search and record all runs in run_record dictionnary \n",
        "# Important: perform search in logarithmic space!\n",
        "for _, lr in enumerate(learning_rates):\n",
        "    for _, epochs in enumerate(anneal_epochs):\n",
        "        for _, reg in enumerate(regs):\n",
        "            loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "            optimizer = optim.SGD(lenet_model.parameters(), lr=lr, weight_decay=reg)\n",
        "\n",
        "            print(f'\\nlearning_rate: {lr}   aneal_epochs: {epochs}   weight_decay: {reg}')\n",
        "            loss_history, train_history, val_history = train_model(lenet_model, train_aug_loader, val_loader, loss, optimizer, 5, epochs, anneal_coeff)\n",
        "\n",
        "            run_record[Hyperparams(lr, epochs, reg)] = RunResult(lenet_model, train_history, val_history, val_history[-1])\n",
        "\n",
        "\n",
        "# TODO: Your code here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6xExdw8JB1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2508f78e-cf3e-4073-f63a-add4f26cdbd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best validation accuracy: 0.84, best hyperparams: Hyperparams(learning_rate=0.001, anneal_epochs=1, reg=0.001)\n"
          ]
        }
      ],
      "source": [
        "best_val_accuracy = None\n",
        "best_hyperparams = None\n",
        "best_run = None\n",
        "\n",
        "for hyperparams, run_result in run_record.items():\n",
        "    if best_val_accuracy is None or best_val_accuracy < run_result.final_val_accuracy:\n",
        "        best_val_accuracy = run_result.final_val_accuracy\n",
        "        best_hyperparams = hyperparams\n",
        "        best_run = run_result\n",
        "        \n",
        "print(\"Best validation accuracy: %4.2f, best hyperparams: %s\" % (best_val_accuracy, best_hyperparams))\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOmsR0uVgtgf"
      },
      "source": [
        "# Свободное упражнение - догоним и перегоним LeNet!\n",
        "\n",
        "Попробуйте найти архитектуру и настройки тренировки, чтобы выступить лучше наших бейзлайнов.\n",
        "\n",
        "Что можно и нужно попробовать:\n",
        "- BatchNormalization (для convolution layers он в PyTorch называется [batchnorm2d](https://pytorch.org/docs/stable/nn.html#batchnorm2d))\n",
        "- Изменить количество слоев и их толщину\n",
        "- Изменять количество эпох тренировки\n",
        "- Попробовать и другие агментации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSVhD747icoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7497844e-1060-491b-ea8b-c3e1183d4e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 0.564071, Train accuracy: 0.826337, Val accuracy: 0.837008\n",
            "Average loss: 0.562074, Train accuracy: 0.828399, Val accuracy: 0.836939\n",
            "Average loss: 0.563961, Train accuracy: 0.826269, Val accuracy: 0.836871\n",
            "Average loss: 0.563728, Train accuracy: 0.826583, Val accuracy: 0.836530\n",
            "Average loss: 0.562420, Train accuracy: 0.828453, Val accuracy: 0.837758\n",
            "Average loss: 0.561960, Train accuracy: 0.827839, Val accuracy: 0.837008\n"
          ]
        }
      ],
      "source": [
        "best_model = nn.Sequential(\n",
        "    nn.Conv2d(3, 6, 5),\n",
        "    nn.BatchNorm2d(6),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(6, 16, 5),\n",
        "    nn.BatchNorm2d(16),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(2),    \n",
        "    Flattener(),\n",
        "    nn.Linear(400, 120),\n",
        "    nn.BatchNorm2d(120),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(120, 84),\n",
        "    nn.BatchNorm2d(84),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(84, 10),\n",
        "    # nn.LogSoftmax(dim=-1)\n",
        "          )\n",
        "best_model.type(torch.cuda.FloatTensor)\n",
        "best_model.to(device)\n",
        "\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "optimizer = optim.SGD(best_model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
        "loss_history, train_history, val_history = train_model(best_model, train_aug_loader, val_loader, loss, optimizer, 10, 1, 0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubeKgBcnhx7N"
      },
      "source": [
        "# Финальный аккорд - проверим лучшую модель на test set\n",
        "\n",
        "В качестве разнообразия - напишите код для прогона модели на test set вы.\n",
        "\n",
        "В результате вы должны натренировать модель, которая покажет более **90%** точности на test set.  \n",
        "Как водится, лучший результат в группе получит дополнительные баллы!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIqM1kdeh-hd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "331d0890-b905-46a4-efbd-f74a031a1cc2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-525dd58a793b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO Write the code to compute accuracy on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_test_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final test accuracy - \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_test_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-e7bd056b0875>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mx_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0my_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
          ]
        }
      ],
      "source": [
        "# TODO Write the code to compute accuracy on test set\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size)\n",
        "final_test_accuracy = compute_accuracy(best_model, test_loader)\n",
        "print(\"Final test accuracy - \", final_test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfH6qip6kVX_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}